{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import from_networkx, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import florah\n",
    "from florah_analysis import envs, utils, preprocess, sampling\n",
    "from florah_analysis import tree_utils\n",
    "\n",
    "from ml_collections import config_flags\n",
    "from absl import flags, logging\n",
    "\n",
    "import training_utils, models, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CONFIG = config_flags.DEFINE_config_file('my_config')\n",
    "FLAG = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m FLAG\u001b[39m.\u001b[39;49mconfig\n",
      "File \u001b[0;32m~/miniconda3/envs/geometric/lib/python3.11/site-packages/absl/flags/_flagvalues.py:491\u001b[0m, in \u001b[0;36mFlagValues.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    489\u001b[0m fl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flags()\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m fl:\n\u001b[0;32m--> 491\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m__hiddenflags\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    493\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: config"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_path = '/mnt/ceph/users/tnguyen/florah/datasets/experiments/GUREFT05-Nanc1.pkl'\n",
    "with open(dset_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# convert networkx to pytorch geometric\n",
    "data = [from_networkx(d) for d in data]\n",
    "\n",
    "def prepare_dataloader(data, train_frac=0.8, batch_size=1024, num_workers=1):\n",
    "\n",
    "    num_total = len(data)\n",
    "    num_train = int(num_total * train_frac)\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # calculate the normaliziation statistics\n",
    "    x = torch.cat([d.x for d in data[:num_train]])\n",
    "    x_mean = x.mean(dim=0)\n",
    "    x_std = x.std(dim=0)\n",
    "    norm_dict = {\"x_mean\": x_mean.numpy(), \"x_std\": x_std.numpy()}\n",
    "    for d in data:\n",
    "        d.x = (d.x - x_mean) / x_std\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        data[:num_train], batch_size=batch_size, shuffle=True, \n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(\n",
    "        data[num_train:], batch_size=batch_size, shuffle=False, \n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = generators.SequenceClassifier(\n",
    "    input_size=input_size, \n",
    "    num_classes=num_classes,\n",
    "    sum_features=sum_features, \n",
    "    num_samples_per_graph=num_samples_per_graph,\n",
    "    d_time=d_time, \n",
    "    featurizer_args=feautrizer_args,\n",
    "    classifier_args=classifier_args,\n",
    "    optimizer_args=optimizer_args,\n",
    "    scheduler_args=scheduler_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/test\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                  | Params\n",
      "----------------------------------------------------------\n",
      "0 | featurizer      | TransformerFeaturizer | 397 K \n",
      "1 | time_projection | Linear                | 256   \n",
      "2 | classifier      | MLPClassifier         | 49.7 K\n",
      "----------------------------------------------------------\n",
      "447 K     Trainable params\n",
      "0         Non-trainable params\n",
      "447 K     Total params\n",
      "1.791     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 125/125 [00:07<00:00, 15.93it/s, v_num=0, train_loss_step=0.311, train_acc_step=0.857, val_loss_step=0.473, val_acc_step=0.833, val_loss_epoch=0.426, val_acc_epoch=0.925, train_loss_epoch=0.181, train_acc_epoch=0.938] \n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1000\n",
    "max_steps = 100000\n",
    "patience = 50\n",
    "grad_clip = 0.5\n",
    "log_dir = 'logs/'\n",
    "name = 'test'\n",
    "\n",
    "callbacks = [\n",
    "    pl.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience, mode='min', verbose=True),\n",
    "    pl.callbacks.ModelCheckpoint(\n",
    "        monitor='val_loss', save_top_k=5, mode='min',\n",
    "        save_weights_only=False)\n",
    "    pl.callbacks.LearningRateMonitor(\"epoch\"),\n",
    "]\n",
    "logger=pl_loggers.TensorBoardLogger(log_dir, name=name)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    max_epochs=max_epochs,\n",
    "    gradient_clip_val=grad_clip,\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
